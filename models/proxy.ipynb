{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import time\n",
    "from sklearn.linear_model import LinearRegression"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_proxy = pd.read_csv('..\\\\models_data\\\\ibes_eps_semi_annual_by_date_2003_2024.csv')\n",
    "df = pd.read_csv('..\\\\models_data\\\\stock_price_monthly_2003_2024.csv')\n",
    "df = df.dropna(subset=[\"past_return\", \"past_return_skip\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "start_date = '2011-01'\n",
    "rebalance = 6\n",
    "end_date_pd = pd.to_datetime(start_date) + pd.DateOffset(months=rebalance)\n",
    "end_date = end_date_pd.strftime('%Y-%m')\n",
    "end_date\n",
    "\n",
    "# Ensure FPEDATS is in datetime format\n",
    "df_proxy['FPEDATS'] = pd.to_datetime(df_proxy['FPEDATS'])\n",
    "\n",
    "# Format to 'YYYY-MM' format\n",
    "df_proxy['FPEDATS'] = df_proxy['FPEDATS'].dt.strftime('%Y-%m')\n",
    "df_proxy= df_proxy.drop(columns=['Year'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Set multi-index on ['date', 'NCUSIP'] and sort for efficient slicing\n",
    "df = df.set_index(['date', 'NCUSIP'])\n",
    "df.sort_index(inplace=True)\n",
    "\n",
    "# Pre-index by date: build a dictionary with date keys for fast lookup in the formation period\n",
    "dates = df.index.get_level_values('date').unique()\n",
    "df_by_date = {date: df.loc[date] for date in dates}\n",
    "\n",
    "VW = False   # Value-weighted flag\n",
    "SKIP = False # Skip flag\n",
    "rebalance = 6"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Formation period: retrieve data for the formation period using the pre-indexed dictionary\n",
    "df1 = df_by_date[start_date].copy()\n",
    "sort_col = \"past_return_skip\" if SKIP else \"past_return\"\n",
    "df1['rank'] = df1[sort_col].rank(method=\"first\", ascending=False)\n",
    "# Classify stocks: Winners (top 10%), Losers (bottom 10%), Neutral otherwise\n",
    "df1['portfolio'] = np.where(\n",
    "    df1['rank'] <= np.percentile(df1['rank'], 10), 'W',\n",
    "    np.where(df1['rank'] >= np.percentile(df1['rank'], 90), 'L', 'N')\n",
    ")\n",
    "# Select winners and losers portfolios\n",
    "buy = df1[df1['portfolio'] == 'W'].copy()\n",
    "sell = df1[df1['portfolio'] == 'L'].copy()\n",
    "\n",
    "# between start_date and end_date\n",
    "df_proxy1 = df_proxy[(df_proxy['FPEDATS'] >= start_date) & (df_proxy['FPEDATS'] < end_date)].copy()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\"Buy Index:\", buy.index)\n",
    "print(\"Sell Index:\", sell.index)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "buy = buy.reset_index()\n",
    "sell = sell.reset_index()\n",
    "buy.sort_values('rank', inplace=True)\n",
    "buy.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# get unqiue NCUSIP and TICKER pairs\n",
    "_df1 = df1.copy().reset_index()\n",
    "_df1_unique = _df1[['TICKER', 'NCUSIP']].drop_duplicates()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Drop FPEDATS and FPI columns if they exist\n",
    "df_proxy1 = df_proxy1.drop(columns=['FPEDATS', 'FPI'], errors='ignore')\n",
    "\n",
    "# Merge with df_proxy1 to find missing pairs\n",
    "merged = _df1_unique.merge(df_proxy1, left_on=['TICKER', 'NCUSIP'], right_on=['OFTIC', 'CUSIP'], how='left', indicator=True)\n",
    "\n",
    "# Select missing pairs and add them with NUMEST = 0\n",
    "missing_rows = merged[merged['_merge'] == 'left_only'][['TICKER', 'NCUSIP']]\n",
    "missing_rows = missing_rows.rename(columns={'TICKER': 'OFTIC', 'NCUSIP': 'CUSIP'})\n",
    "missing_rows['NUMEST'] = 0\n",
    "\n",
    "# Append missing rows efficiently\n",
    "df_proxy1 = pd.concat([df_proxy1, missing_rows], ignore_index=True)\n",
    "\n",
    "# drop na\n",
    "df_proxy1 = df_proxy1.dropna(subset=['OFTIC', 'CUSIP'])\n",
    "df_proxy1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Ensure columns are strings and properly formatted\n",
    "df_proxy1['CUSIP'] = df_proxy1['CUSIP'].astype(str).str.zfill(8)\n",
    "df_proxy1['OFTIC'] = df_proxy1['OFTIC'].astype(str)\n",
    "\n",
    "_df1['NCUSIP'] = _df1['NCUSIP'].astype(str).str.zfill(8)\n",
    "_df1['TICKER'] = _df1['TICKER'].astype(str)\n",
    "\n",
    "# Merge on CUSIP <-> NCUSIP and OFTIC <-> TICKER\n",
    "df_proxy1 = df_proxy1.merge(\n",
    "    _df1[['NCUSIP', 'TICKER', 'ME', 'NasdaqDummy']], \n",
    "    left_on=['CUSIP', 'OFTIC'], \n",
    "    right_on=['NCUSIP', 'TICKER'], \n",
    "    how='left'\n",
    ")\n",
    "\n",
    "# Drop redundant columns after merge\n",
    "df_proxy1.drop(columns=['NCUSIP', 'TICKER'], inplace=True)\n",
    "df_proxy1 = df_proxy1.dropna(subset=['ME'])\n",
    "\n",
    "# Display result\n",
    "df_proxy1\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# linear regression ln(1+ # of Analyst) = β0​+β1*​ln(Size​)+β2*​NasdaqDummy\n",
    "\n",
    "# Create a new column with the natural logarithm of the number of analysts\n",
    "df_proxy1['ln_analysts'] = np.log1p(df_proxy1['NUMEST'])\n",
    "# Create a new column with the natural logarithm of the market capitalization\n",
    "df_proxy1['ln_ME'] = np.log(df_proxy1['ME'])\n",
    "\n",
    "\n",
    "# apply linear regression\n",
    "X = df_proxy1[['ln_ME', 'NasdaqDummy']]\n",
    "y = df_proxy1['ln_analysts']\n",
    "reg = LinearRegression().fit(X, y)\n",
    "beta0 = reg.intercept_\n",
    "beta1, beta2 = reg.coef_\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "import numpy as np\n",
    "from sklearn.metrics import mean_squared_error, r2_score\n",
    "\n",
    "# Manually compute predicted values and ensure predictions are non-negative\n",
    "y_pred = reg.predict(X)\n",
    "y_pred = np.maximum(y_pred, 0)  # Ensure no negative predictions\n",
    "df_proxy1[\"predicted_ln_analysts\"] = y_pred\n",
    "\n",
    "# Compute RMSE\n",
    "rmse = np.sqrt(mean_squared_error(y, y_pred))\n",
    "r2 = r2_score(y, y_pred)\n",
    "\n",
    "\n",
    "# Visualization\n",
    "plt.figure(figsize=(10, 6))\n",
    "\n",
    "# Scatter plot of actual data points\n",
    "sns.scatterplot(x=df_proxy1['ln_ME'], y=df_proxy1['ln_analysts'], hue=df_proxy1['NasdaqDummy'], alpha=0.7, palette='coolwarm')\n",
    "\n",
    "# Regression lines\n",
    "ln_ME_range = np.linspace(df_proxy1['ln_ME'].min(), df_proxy1['ln_ME'].max(), 100)\n",
    "\n",
    "# Nasdaq regression line (orange)\n",
    "ln_analysts_predicted_nasdaq = beta0 + beta1 * ln_ME_range + beta2 * 1  # NasdaqDummy = 1\n",
    "plt.plot(ln_ME_range, np.maximum(ln_analysts_predicted_nasdaq, 0), color='orange', linewidth=2, label=\"Nasdaq Regression\")\n",
    "\n",
    "# Non-Nasdaq regression line (blue)\n",
    "ln_analysts_predicted_non_nasdaq = beta0 + beta1 * ln_ME_range + beta2 * 0  # NasdaqDummy = 0\n",
    "plt.plot(ln_ME_range, np.maximum(ln_analysts_predicted_non_nasdaq, 0), color='blue', linewidth=2, label=\"Non-Nasdaq Regression\")\n",
    "\n",
    "# Add Betas & RMSE as text on the plot\n",
    "textstr = (rf\"$\\ln(1 + \\text{{# Analysts}}) = {beta0:.4f} + {beta1:.4f} * \\ln(\\text{{Size}}) + {beta2:.4f} * \\text{{Nasdaq}}$\"\n",
    "           f\"\\nRMSE = {rmse:.4f} \\nR2 = {r2:.4f}\")\n",
    "plt.text(0.05, 0.95, textstr, transform=plt.gca().transAxes, fontsize=12,\n",
    "         verticalalignment='top', bbox=dict(boxstyle=\"round,pad=0.3\", edgecolor=\"black\", facecolor=\"white\"))\n",
    "\n",
    "# Labels and title\n",
    "plt.xlabel(\"ln(Size) (Market Capitalization)\")\n",
    "plt.ylabel(\"ln(1 + # of Analysts)\")\n",
    "plt.title(f\"Linear Regression: Analysts vs. Market Capitalization {start_date} - {end_date}\")\n",
    "plt.legend(title=\"Nasdaq Dummy\", loc='upper left', bbox_to_anchor=(1.05, 1), borderaxespad=0)\n",
    "plt.grid(True)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_proxy1[\"predicted_analysts\"] = np.expm1(df_proxy1[\"predicted_ln_analysts\"])\n",
    "df_proxy1[\"residuals\"] = df_proxy1[\"NUMEST\"] - df_proxy1[\"predicted_analysts\"]\n",
    "\n",
    "df_proxy1.describe()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_proxy1.sort_values('residuals', ascending=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# # merge residuals col with buy and sell\n",
    "buy = buy.merge(df_proxy1[['OFTIC', 'CUSIP', 'residuals']], left_on=['NCUSIP', 'TICKER'], right_on=['CUSIP', 'OFTIC'], how='left')\n",
    "sell = sell.merge(df_proxy1[['OFTIC', 'CUSIP', 'residuals']], left_on=['NCUSIP', 'TICKER'], right_on=['CUSIP', 'OFTIC'], how='left')\n",
    "buy = buy.drop(columns=['CUSIP', 'OFTIC'], errors='ignore')\n",
    "sell = sell.drop(columns=['CUSIP', 'OFTIC'], errors='ignore')\n",
    "\n",
    "# drop rows with NaN residuals\n",
    "buy = buy.dropna(subset=['residuals'])\n",
    "sell = sell.dropna(subset=['residuals'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# long bottom 25% of residual winners\n",
    "buy['portfolio'] = np.where(\n",
    "    buy['residuals'] <= np.percentile(buy['residuals'], 25), 'W','N')\n",
    "\n",
    "# short bottom 25% of residual losers\n",
    "sell['portfolio'] = np.where(\n",
    "    sell['residuals'] <= np.percentile(sell['residuals'], 25), 'L','N')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "sell.sort_values('residuals', inplace=True)\n",
    "sell"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "buy = buy[buy['portfolio'] == 'W']\n",
    "sell = sell[sell['portfolio'] == 'L']\n",
    "\n",
    "# Assign weights (equal-weighted or value-weighted)\n",
    "buy.loc[:, 'weight'] = buy['ME'] / buy['ME'].sum() if VW else 1 / len(buy)\n",
    "sell.loc[:, 'weight'] = sell['ME'] / sell['ME'].sum() if VW else 1 / len(sell)\n",
    "\n",
    "buy = buy.set_index(\"NCUSIP\")\n",
    "sell = sell.set_index(\"NCUSIP\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Retrieve holding period data using multi-index slicing\n",
    "idx = pd.IndexSlice\n",
    "df_hold = df.loc[idx[start_date:end_date, :], :]\n",
    "# --- Vectorized cumulative return computation ---\n",
    "# Reset index so that 'NCUSIP' becomes a column\n",
    "df_hold_reset = df_hold.reset_index()\n",
    "# Create a new column for 1 + RET\n",
    "df_hold_reset['one_plus_ret'] = 1 + df_hold_reset['RET']\n",
    "# Compute cumulative product per stock over the holding period and subtract 1\n",
    "accu_returns = df_hold_reset.groupby('NCUSIP')['one_plus_ret'].prod() - 1\n",
    "# Compute weighted returns by aligning on stock identifier\n",
    "buy_return = (buy['weight'] * accu_returns.reindex(buy.index)).sum()\n",
    "sell_return = (sell['weight'] * accu_returns.reindex(sell.index)).sum()\n",
    "# Overall portfolio return: long winners minus short losers\n",
    "portfolio_return = buy_return - sell_return\n",
    "\n",
    "color = '\\033[92m' if portfolio_return > 0 else '\\033[91m'\n",
    "reset = '\\033[0m'\n",
    "print(f\"{start_date} {end_date} {color}{round(portfolio_return * 100, 2)}%{reset}\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "fin",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.16"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
